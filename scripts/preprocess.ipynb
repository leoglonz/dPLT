{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data\n",
    "\n",
    "-- Land subsidence project: 15 March 2025 --\n",
    "\n",
    "---\n",
    "\n",
    "#### Create train/test pickle files for dMG-dPLT\n",
    "\n",
    "Current Operations:\n",
    "- Reformat dataframes.\n",
    "- Keep only minimally available temporal data shared by all sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Paths\n",
    "# 1. Station information\n",
    "# 2. Land subsidence  measurements (monthly)\n",
    "# 3. Groundwater level measurements (monthly)\n",
    "# 4. Lithology, geological parameters per aquifer layer\n",
    "\n",
    "station_path = '/projects/mhpi/leoglonz/data/extracted/land_subsidence/all_stations_info_subsidence.csv'\n",
    "ls_path = '/projects/mhpi/leoglonz/data/extracted/land_subsidence/all_stations_monthly_subsidence.csv'\n",
    "gw_path = '/projects/mhpi/leoglonz/data/extracted/land_subsidence/all_stations_monthly_water_levels.csv'\n",
    "geo_path = '/projects/mhpi/leoglonz/data/extracted/land_subsidence/geology_layers.csv'\n",
    "\n",
    "save_path = '/projects/mhpi/leoglonz/data/extracted/land_subsidence/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(6712)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw['station_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available keys:\n",
      " ls: Index(['vert_mm_avg', 'vert_std_mm_avg', 'vert_mm_first', 'date',\n",
      "       'change_mm_avg', 'change_mm_first', 'station_id'],\n",
      "      dtype='object')\n",
      " gw: Index(['station_id', 'station_name', 'date', 'wlm_rpe', 'wlm_rpe_change',\n",
      "       'gwe', 'gwe_change', 'station_count', 'interpolated'],\n",
      "      dtype='object')\n",
      " geo: Index(['station_id', 'station_lat', 'station_lon', 'geology_id', 'distance_m',\n",
      "       'geology_x_feet', 'geology_y_feet', 'layer_number', 'depth_midpoint',\n",
      "       'percent_coarse', 'void_ratio', 'compression_index',\n",
      "       'recompression_index', 'OCR', 'hydraulic_conductivity',\n",
      "       'coefficient_vol_compressibility', 'initial_effective_stress',\n",
      "       'thickness', 'is_fine_grained', 'is_clay', 'is_corcoran_clay'],\n",
      "      dtype='object')\n",
      "\n",
      "Available data:\n",
      " 16 sites,\n",
      " 245 months\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "### Read data\n",
    "stations = pd.read_csv(station_path)\n",
    "ls = pd.read_csv(ls_path)\n",
    "gw = pd.read_csv(gw_path)\n",
    "geo = pd.read_csv(geo_path)\n",
    "\n",
    "\n",
    "### Format dataframes\n",
    "ls = ls.rename(columns=str.lower)\n",
    "ls['date'] = pd.to_datetime(ls['date'])\n",
    "ls['date'] = ls['date'].dt.date\n",
    "\n",
    "gw = gw.rename(columns={\n",
    "    'Subsidence_Station_ID':'station_id',\n",
    "    'Subsidence_Station_Name':'station_name',\n",
    "    'Month':'date',\n",
    "    }).rename(columns=str.lower)\n",
    "gw['date'] = pd.to_datetime(gw['date'], format='%Y-%m')\n",
    "gw['date'] = gw['date'].dt.date\n",
    "\n",
    "print(f\"Available keys:\\n ls: {ls.columns}\\n gw: {gw.columns}\\n geo: {geo.columns}\\n\")\n",
    "\n",
    "avail_months = min(len(ls['date'].unique()), len(gw['date'].unique()))\n",
    "print(f\"Available data:\\n {len(ls['station_id'].unique())} sites,\\n {avail_months} months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# --- Available time ranges per site --- #\n",
      "DIXN: 2012-07-01 - 2024-10-01\n",
      "P208: 2006-04-01 - 2024-03-01\n",
      "P266: 2005-06-01 - 2024-03-01\n",
      "P267: 2005-05-01 - 2024-10-01\n",
      "P268: 2005-05-01 - 2024-09-01\n",
      "P269: 2008-08-01 - 2024-04-01\n",
      "P270: 2005-11-01 - 2024-03-01\n",
      "P271: 2004-07-01 - 2024-09-01\n",
      "P275: 2006-08-01 - 2024-05-01\n",
      "P276: 2006-04-01 - 2024-10-01\n",
      "P336: 2007-10-01 - 2024-10-01\n",
      "P339: 2007-08-01 - 2024-10-01\n",
      "P344: 2006-10-01 - 2024-10-01\n",
      "P345: 2005-11-01 - 2024-10-01\n",
      "P349: 2006-03-01 - 2024-10-01\n",
      "VCVL: 2012-10-01 - 2024-11-01\n",
      "# -------------------------------- #\n",
      "Minimum availability: 2012-10-01 - 2024-03-01\n",
      "\n",
      "Aligning time ranges...\n",
      "New data dimensions:\n",
      " 16 sites,\n",
      " 137 months\n"
     ]
    }
   ],
   "source": [
    "### Get time ranges for each site:\n",
    "print('# --- Available time ranges per site --- #')\n",
    "time_ranges = []\n",
    "min_all = pd.Timestamp('2000-01-01').date()\n",
    "max_all = pd.Timestamp('2100-01-01').date()\n",
    "\n",
    "for site in ls['station_id'].unique():\n",
    "    site_ls = ls[ls['station_id'] == site]\n",
    "    site_gw = gw[gw['station_id'] == site]\n",
    "    min_date = max(site_ls['date'].min(), site_gw['date'].min())\n",
    "    max_date = min(site_ls['date'].max(), site_gw['date'].max())\n",
    "    time_ranges.append([site, min_date, max_date])\n",
    "\n",
    "    # print(max_all, max_date)\n",
    "    min_all = max(min_all, min_date)\n",
    "    max_all = min(max_all, max_date)\n",
    "\n",
    "    print(f\"{site}: {min_date} - {max_date}\")\n",
    "\n",
    "print('# -------------------------------- #')\n",
    "print(f\"Minimum availability: {min_all} - {max_all}\")\n",
    "\n",
    "### Align time ranges\n",
    "print(\"\\nAligning time ranges...\")\n",
    "ls_aligned = ls[(ls['date'] >= min_all) & (ls['date'] <= max_all)]  # Remove first day of the new range\n",
    "gw_aligned = gw[(gw['date'] >= min_all) & (gw['date'] <= max_all)]\n",
    "\n",
    "\n",
    "avail_months = min(len(ls_aligned['date'].unique()), len(gw_aligned['date'].unique()))\n",
    "print(f\"New data dimensions:\\n {len(ls_aligned['station_id'].unique())} sites,\\n {avail_months} months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimming all sites to 9 layers\n"
     ]
    }
   ],
   "source": [
    "### Get max number of available layers accross sites:\n",
    "# Note: later make the other layers 0 thickness if unavailable\n",
    "\n",
    "min_layer = 100\n",
    "for site in ls['station_id'].unique():\n",
    "    geo_station = geo[geo['station_id'] == site]\n",
    "\n",
    "    min_layer = min(min_layer, geo_station['layer_number'].max()) \n",
    "\n",
    "print(f\"Trimming all sites to {min_layer} layers\")\n",
    "geo_aligned = geo[geo['layer_number'] <= min_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra rows in df2:\n",
      "      vert_mm_avg  vert_std_mm_avg  vert_mm_first        date  change_mm_avg  \\\n",
      "145    -51.137333         7.369000         -54.81  2024-11-01       4.874925   \n",
      "146    -51.652903         7.446129         -51.73  2024-12-01      -0.515570   \n",
      "147    -49.265161         6.541935         -54.25  2025-01-01       2.387742   \n",
      "357    -12.114667         7.173000         -12.61  2024-04-01      -0.437570   \n",
      "358    -12.227097         7.264839         -13.65  2024-05-01      -0.112430   \n",
      "...           ...              ...            ...         ...            ...   \n",
      "3186     9.541935         7.444194          11.20  2012-07-01            NaN   \n",
      "3187    12.232903         7.452903           9.54  2012-08-01       2.690968   \n",
      "3188    14.210333         7.490667           7.75  2012-09-01       1.977430   \n",
      "3327   -25.059355         7.360968         -29.54  2024-12-01      -6.734355   \n",
      "3328   -24.675806         6.295161         -28.03  2025-01-01       0.383548   \n",
      "\n",
      "      change_mm_first station_id  \n",
      "145              0.86       DIXN  \n",
      "146              3.08       DIXN  \n",
      "147             -2.52       DIXN  \n",
      "357              2.71       P208  \n",
      "358             -1.04       P208  \n",
      "...               ...        ...  \n",
      "3186              NaN       VCVL  \n",
      "3187            -1.66       VCVL  \n",
      "3188            -1.79       VCVL  \n",
      "3327            -5.98       VCVL  \n",
      "3328             1.51       VCVL  \n",
      "\n",
      "[92 rows x 7 columns]\n",
      "Missing rows in df2:\n",
      "     station_id      station_name        date     wlm_rpe  wlm_rpe_change  \\\n",
      "17         DIXN  DixonCity_CA2012  2013-12-01   78.259532        0.423489   \n",
      "78         DIXN  DixonCity_CA2012  2019-01-01   71.719338        7.425427   \n",
      "82         DIXN  DixonCity_CA2012  2019-05-01   51.000000      -14.265000   \n",
      "148        P208  SaltCanyonCN2006  2006-03-01  130.740000             NaN   \n",
      "157        P208  SaltCanyonCN2006  2006-12-01  130.740000        0.000000   \n",
      "...         ...               ...         ...         ...             ...   \n",
      "3302       VCVL  Vacaville_CA2012  2018-03-01  133.120000        0.000000   \n",
      "3303       VCVL  Vacaville_CA2012  2018-04-01  113.404000      -19.716000   \n",
      "3316       VCVL  Vacaville_CA2012  2019-05-01  133.120000       19.716000   \n",
      "3319       VCVL  Vacaville_CA2012  2019-08-01  133.120000        0.000000   \n",
      "3335       VCVL  Vacaville_CA2012  2020-12-01  133.120000        0.000000   \n",
      "\n",
      "            gwe  gwe_change  station_count  interpolated  \n",
      "17    21.847482   -7.995827              0          True  \n",
      "78    27.124840   12.946474              0          True  \n",
      "82    11.000000    6.945000              0          True  \n",
      "148   77.240000         NaN              2         False  \n",
      "157   72.979907    0.786180              0          True  \n",
      "...         ...         ...            ...           ...  \n",
      "3302        NaN         NaN              1         False  \n",
      "3303  24.404000         NaN              6         False  \n",
      "3316  63.720000   38.916000              1         False  \n",
      "3319  58.120000   -2.000000              1         False  \n",
      "3335  61.761228    2.241228              0          True  \n",
      "\n",
      "[146 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "### See missing rows in ls data ###\n",
    "df1 = gw.copy()\n",
    "df2 = ls.copy()\n",
    "\n",
    "# Find rows in df2 that are not in df1\n",
    "extra_rows = df2[~df2.set_index(['station_id', 'date']).index.isin(df1.set_index(['station_id', 'date']).index)]\n",
    "\n",
    "# Find rows in df1 that are not in df2\n",
    "missing_rows = df1[~df1.set_index(['station_id', 'date']).index.isin(df2.set_index(['station_id', 'date']).index)]\n",
    "\n",
    "print(\"Extra rows in df2:\")\n",
    "print(extra_rows)\n",
    "\n",
    "print(\"Missing rows in df2:\")\n",
    "print(missing_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge data on ls < gw < geo\n",
    "ls_gw = pd.merge(ls_aligned, gw_aligned, how='left', on=['station_id', 'date'])\n",
    "\n",
    "data = pd.merge(ls_gw, geo_aligned, how='left', on='station_id') \n",
    "\n",
    "data.drop(columns=[\n",
    "    #### Land subsidence ####\n",
    "    'vert_mm_avg',\n",
    "    'vert_std_mm_avg',\n",
    "    'vert_mm_first',\n",
    "    'change_mm_avg',\n",
    "    #### Groundwater ####\n",
    "    'station_name',\n",
    "    'wlm_rpe',\n",
    "    'wlm_rpe_change',\n",
    "    'gwe',\n",
    "    'station_count',\n",
    "    'interpolated',\n",
    "    #### Geology ####\n",
    "    'station_lat',\n",
    "    'station_lon',\n",
    "    'geology_id',\n",
    "    'distance_m',\n",
    "    'geology_x_feet',\n",
    "    'geology_y_feet',\n",
    "    'depth_midpoint',\n",
    "    'is_fine_grained',\n",
    "    'is_clay',\n",
    "    'is_corcoran_clay',\n",
    "], inplace=True)\n",
    "\n",
    "data.rename(columns={\n",
    "    'change_mm_first':'subsidence',\n",
    "    'gwe_change':'gwe',\n",
    "}, inplace=True)\n",
    "\n",
    "data = data.sort_values(by=['date', 'station_id', 'layer_number']).reset_index(drop=True)\n",
    "\n",
    "### Save combined data\n",
    "data.to_csv(os.path.join(save_path, 'ls_combined.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>subsidence</th>\n",
       "      <th>station_id</th>\n",
       "      <th>gwe</th>\n",
       "      <th>layer_number</th>\n",
       "      <th>percent_coarse</th>\n",
       "      <th>void_ratio</th>\n",
       "      <th>compression_index</th>\n",
       "      <th>recompression_index</th>\n",
       "      <th>OCR</th>\n",
       "      <th>hydraulic_conductivity</th>\n",
       "      <th>coefficient_vol_compressibility</th>\n",
       "      <th>initial_effective_stress</th>\n",
       "      <th>thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>3.08</td>\n",
       "      <td>DIXN</td>\n",
       "      <td>19.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.193599</td>\n",
       "      <td>0.395733</td>\n",
       "      <td>0.059360</td>\n",
       "      <td>1.749515</td>\n",
       "      <td>9.757353e-10</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>30.772213</td>\n",
       "      <td>8.5344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>3.08</td>\n",
       "      <td>DIXN</td>\n",
       "      <td>19.21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.184455</td>\n",
       "      <td>0.389637</td>\n",
       "      <td>0.058446</td>\n",
       "      <td>1.679840</td>\n",
       "      <td>9.420891e-10</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>75.048388</td>\n",
       "      <td>3.6576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>3.08</td>\n",
       "      <td>DIXN</td>\n",
       "      <td>19.21</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.781255</td>\n",
       "      <td>0.096251</td>\n",
       "      <td>0.009625</td>\n",
       "      <td>1.077790</td>\n",
       "      <td>8.977119e-06</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>174.025301</td>\n",
       "      <td>13.1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>3.08</td>\n",
       "      <td>DIXN</td>\n",
       "      <td>19.21</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.142164</td>\n",
       "      <td>0.361443</td>\n",
       "      <td>0.054216</td>\n",
       "      <td>1.391996</td>\n",
       "      <td>8.009529e-10</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>284.659556</td>\n",
       "      <td>26.5176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>3.08</td>\n",
       "      <td>DIXN</td>\n",
       "      <td>19.21</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.118847</td>\n",
       "      <td>0.345898</td>\n",
       "      <td>0.051885</td>\n",
       "      <td>1.254964</td>\n",
       "      <td>7.323944e-10</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>403.628512</td>\n",
       "      <td>4.5720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  subsidence station_id    gwe  layer_number  percent_coarse  \\\n",
       "0  2012-10-01        3.08       DIXN  19.21             1               0   \n",
       "1  2012-10-01        3.08       DIXN  19.21             2               0   \n",
       "2  2012-10-01        3.08       DIXN  19.21             3             100   \n",
       "3  2012-10-01        3.08       DIXN  19.21             4               0   \n",
       "4  2012-10-01        3.08       DIXN  19.21             5               0   \n",
       "\n",
       "   void_ratio  compression_index  recompression_index       OCR  \\\n",
       "0    1.193599           0.395733             0.059360  1.749515   \n",
       "1    1.184455           0.389637             0.058446  1.679840   \n",
       "2    0.781255           0.096251             0.009625  1.077790   \n",
       "3    1.142164           0.361443             0.054216  1.391996   \n",
       "4    1.118847           0.345898             0.051885  1.254964   \n",
       "\n",
       "   hydraulic_conductivity  coefficient_vol_compressibility  \\\n",
       "0            9.757353e-10                         0.000372   \n",
       "1            9.420891e-10                         0.000370   \n",
       "2            8.977119e-06                         0.000045   \n",
       "3            8.009529e-10                         0.000358   \n",
       "4            7.323944e-10                         0.000350   \n",
       "\n",
       "   initial_effective_stress  thickness  \n",
       "0                 30.772213     8.5344  \n",
       "1                 75.048388     3.6576  \n",
       "2                174.025301    13.1064  \n",
       "3                284.659556    26.5176  \n",
       "4                403.628512     4.5720  "
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data array shape: (137, 16, 9, 11)\n",
      "Data saved to pickle file: /projects/mhpi/leoglonz/data/extracted/land_subsidence/ls_train\n"
     ]
    }
   ],
   "source": [
    "### Convert data to numpy arrays ###\n",
    "\n",
    "dates = data['date'].unique()\n",
    "sites = data['station_id'].unique()\n",
    "layers = data['layer_number'].unique()\n",
    "\n",
    "n_dates = len(dates)\n",
    "n_sites = len(sites)\n",
    "n_layers = len(layers)\n",
    "\n",
    "full_index = pd.MultiIndex.from_product(\n",
    "    [dates, sites, layers],\n",
    "    names=['date', 'station_id', 'layer_number']\n",
    ")\n",
    "\n",
    "data_pivot = data.set_index(['date', 'station_id', 'layer_number'])\n",
    "data_pivot = data_pivot.reindex(full_index).reset_index()\n",
    "\n",
    "feature_columns = [col for col in data.columns if col not in ['date', 'station_id', 'layer_number']]\n",
    "n_features = len(feature_columns)\n",
    "\n",
    "# Fill missing values with 0\n",
    "data_pivot[feature_columns] = data_pivot[feature_columns].fillna(0)\n",
    "\n",
    "data_array = data_pivot[feature_columns].to_numpy().reshape(n_dates, n_sites, n_layers, n_features)\n",
    "print(\"Data array shape:\", data_array.shape)\n",
    "\n",
    "\n",
    "# 1. Attributes (geology)\n",
    "attr_array = data_array[:,:,:,2:]\n",
    "\n",
    "# 2. Groundwater\n",
    "forc_array = attr_array[:,:,0,1]\n",
    "\n",
    "## 3. Target (subsidence)\n",
    "target_array = data_array[:,:,0,0]\n",
    "\n",
    "\n",
    "### Save to pickle file\n",
    "dict = {\n",
    "    'attributes': attr_array,\n",
    "    'forcing': forc_array,\n",
    "    'target': target_array,\n",
    "}\n",
    "\n",
    "path = os.path.join(save_path, 'ls_train')\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(data_array, f)\n",
    "    print(f\"Data saved to pickle file: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
