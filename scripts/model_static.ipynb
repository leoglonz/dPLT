{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfSubsidence = pd.read_csv('/content/SubsidenceYearlyRolling.csv')\n",
    "\n",
    "\n",
    "dfLayers = pd.read_csv('/content/geology_layers_by_station.csv')\n",
    "dfLayers.head()\n",
    "\n",
    "dfWaterlevel = pd.read_csv('/content/DrawdownInterplorlated.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "class LayeredSubsidenceModel:\n",
    "    def __init__(self, layer_data):\n",
    "        self.layers = layer_data.sort_values('layer_number')\n",
    "        self.num_layers = len(layer_data)\n",
    "        self.total_thickness = self.layers['thickness'].sum()\n",
    "\n",
    "        # set constants\n",
    "        self.water_unit_weight = 9.81  # kN/m³\n",
    "        self.cv_multiplier = 1e7 # Increased consolidation coefficient\n",
    "\n",
    "    def _calculate_cv(self, layer):\n",
    "        cv = (layer['hydraulic_conductivity'] * self.water_unit_weight *\n",
    "              (1 + layer['void_ratio']) * self.cv_multiplier)\n",
    "        return max(cv, 1e-8)  # Ensure minimum value\n",
    "\n",
    "    def _calculate_consolidation_ratio(self, Tv):\n",
    "        if isinstance(Tv, (int, float)):\n",
    "            if Tv < 0.2:\n",
    "                U = 2 * np.sqrt(Tv / np.pi)\n",
    "            else:\n",
    "                U = 1 - (8 / (np.pi**2)) * np.exp(-((np.pi**2) / 4) * Tv)\n",
    "        else:\n",
    "            U = np.where(Tv < 0.2,\n",
    "                        2 * np.sqrt(Tv / np.pi),\n",
    "                        1 - (8 / (np.pi**2)) * np.exp(-((np.pi**2) / 4) * Tv))\n",
    "        return np.clip(U, 0, 1)\n",
    "\n",
    "    def _calculate_layer_settlement(self, layer, delta_p, t):\n",
    "        # Skip calculation if pressure change is zero\n",
    "        if delta_p == 0:\n",
    "            return 0.0\n",
    "\n",
    "        #Calculate stresses\n",
    "        initial_stress = layer['initial_effective_stress']\n",
    "        precons_pressure = initial_stress * layer['OCR']\n",
    "        final_stress = max(initial_stress + delta_p, 0.1 * initial_stress)  # Prevent negative stress\n",
    "\n",
    "        # Calculate ultimate settlement\n",
    "        if final_stress <= precons_pressure:\n",
    "            #Recompression range\n",
    "            settlement = (layer['thickness'] / (1 + layer['void_ratio'])) * \\\n",
    "                        layer['recompression_index'] * \\\n",
    "                        np.log10(final_stress / initial_stress)\n",
    "        else:\n",
    "            # Both recompression and virgin compression\n",
    "            settlement = (layer['thickness'] / (1 + layer['void_ratio'])) * \\\n",
    "                        (layer['recompression_index'] * \\\n",
    "                         np.log10(precons_pressure / initial_stress) + \\\n",
    "                         layer['compression_index'] * \\\n",
    "                         np.log10(final_stress / precons_pressure))\n",
    "\n",
    "        #time factor\n",
    "        cv = self._calculate_cv(layer)\n",
    "        Tv = (cv * t) / (layer['thickness']**2)\n",
    "        U = self._calculate_consolidation_ratio(Tv)\n",
    "\n",
    "        # Scale settlement based on percent coarse\n",
    "        fine_fraction = (100 - layer['percent_coarse']) / 100\n",
    "        settlement *= fine_fraction  # More settlement for fine-grained materials\n",
    "\n",
    "        return settlement * U\n",
    "\n",
    "    def predict_annual_subsidence(self, annual_head_change):\n",
    "        \"\"\"Predict subsidence for one year with improved time steps\"\"\"\n",
    "        if annual_head_change == 0:\n",
    "            return 0.0\n",
    "\n",
    "        # Use more time steps for better accuracy\n",
    "        times = np.linspace(0, 365, 365)  # Daily intervals\n",
    "\n",
    "        # Create head change array (exponential approach to final value)\n",
    "        tau = 30  # Time constant (days)\n",
    "        head_changes = annual_head_change * (1 - np.exp(-times/tau))\n",
    "\n",
    "        total_subsidence = np.zeros_like(times)\n",
    "\n",
    "        # Calculate settlement for each layer\n",
    "        for _, layer in self.layers.iterrows():\n",
    "            for t_idx, t in enumerate(times):\n",
    "                delta_p = head_changes[t_idx] * self.water_unit_weight\n",
    "                settlement = self._calculate_layer_settlement(layer, delta_p, t)\n",
    "                total_subsidence[t_idx] += settlement\n",
    "\n",
    "        # Return final settlement in millimeters\n",
    "        return total_subsidence[-1] * 1000\n",
    "\n",
    "\n",
    "def load_layer_data(data_string):\n",
    "    \"\"\"Convert comma-separated string to DataFrame\"\"\"\n",
    "    # Split the string into lines and parse\n",
    "    lines = data_string.strip().split('\\n')\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        values = line.split(',')\n",
    "        data.append({\n",
    "            'station_id': values[0],\n",
    "            'layer_number': int(values[9]),\n",
    "            'thickness': float(values[11]),\n",
    "            'percent_coarse': float(values[12]),\n",
    "            'void_ratio': float(values[13]),\n",
    "            'compression_index': float(values[14]),\n",
    "            'recompression_index': float(values[15]),\n",
    "            'OCR': float(values[16]),\n",
    "            'hydraulic_conductivity': float(values[17]),\n",
    "            'initial_effective_stress': float(values[18])\n",
    "        })\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class GeologicalSubsidenceModel:\n",
    "    def __init__(self, layer_data):\n",
    "        self.layers = layer_data.sort_values('layer_number').reset_index(drop=True)\n",
    "        self.num_layers = len(layer_data)\n",
    "\n",
    "        # set constants\n",
    "        self.water_unit_weight = 9.81  # kN/m³\n",
    "        self.min_stress = 10.0  # kPa\n",
    "\n",
    "        self._initialize_layer_weights()\n",
    "\n",
    "    def _initialize_layer_weights(self):\n",
    "        weights = []\n",
    "        for _, layer in self.layers.iterrows():\n",
    "            #Calculate weight factors\n",
    "            compressibility = layer['compression_index'] * (1 + layer['void_ratio'])\n",
    "            fine_fraction = (100 - layer['percent_coarse']) / 100\n",
    "            depth_factor = np.exp(-layer['layer_number'] / self.num_layers)\n",
    "\n",
    "            # Combined weight\n",
    "            weight = compressibility * fine_fraction * depth_factor\n",
    "            weights.append(weight)\n",
    "\n",
    "        #Normalize weights\n",
    "        weights = np.array(weights)\n",
    "        self.layer_weights = weights / np.sum(weights)\n",
    "\n",
    "    def predict_subsidence(self, current_change, prev_changes=None):\n",
    "        \"\"\"Predict annual subsidence\"\"\"\n",
    "        total_subsidence = 0\n",
    "\n",
    "        if prev_changes is not None:\n",
    "            historical_effect = 0\n",
    "            for i, change in enumerate(prev_changes):\n",
    "                if pd.notna(change):\n",
    "                    historical_effect += change * np.exp(-(len(prev_changes) - i))\n",
    "            current_change += 0.3 * historical_effect\n",
    "\n",
    "        for i, layer in self.layers.iterrows():\n",
    "            # Calculate effective stress change\n",
    "            depth_factor = np.exp(-layer['layer_number'] / self.num_layers)\n",
    "            stress_change = current_change * self.water_unit_weight * depth_factor\n",
    "\n",
    "            #Apply layer properties\n",
    "            compression = self._calculate_compression(layer, stress_change)\n",
    "\n",
    "            #Add to total with layer weight\n",
    "            total_subsidence += compression * self.layer_weights[i]\n",
    "\n",
    "        return total_subsidence * 1000  # mm\n",
    "\n",
    "    def _calculate_compression(self, layer, stress_change):\n",
    "        \"\"\"Calculate compression for a single layer\"\"\"\n",
    "        if abs(stress_change) < 1e-6:\n",
    "            return 0.0\n",
    "\n",
    "        initial_stress = max(layer['initial_effective_stress'], self.min_stress)\n",
    "        final_stress = max(initial_stress + stress_change, self.min_stress)\n",
    "\n",
    "        cc = layer['compression_index']\n",
    "        cr = layer['recompression_index']\n",
    "        e0 = layer['void_ratio']\n",
    "        ocr = layer['OCR']\n",
    "        precons_pressure = initial_stress * ocr\n",
    "\n",
    "        # dual compression calculations\n",
    "        if final_stress <= precons_pressure:\n",
    "            compression = (layer['thickness'] * cr / (1 + e0)) * \\\n",
    "                         np.log(final_stress / initial_stress)\n",
    "        else:\n",
    "            compression = (layer['thickness'] / (1 + e0)) * \\\n",
    "                         (cr * np.log(precons_pressure / initial_stress) +\n",
    "                          cc * np.log(final_stress / precons_pressure))\n",
    "\n",
    "        #apply fine content scaling\n",
    "        fine_fraction = (100 - layer['percent_coarse']) / 100\n",
    "        compression *= (0.5 + 0.5 * fine_fraction)\n",
    "\n",
    "        return compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_station(station_id, dfLayers, dfWaterlevel, dfSubsidence, lookback=2):\n",
    "    \"\"\"Analyze a single station\"\"\"\n",
    "    # Get station data\n",
    "    station_layers = dfLayers[dfLayers['station_id'] == station_id].copy()\n",
    "    station_subsidence = dfSubsidence[dfSubsidence['station_id'] == station_id].sort_values('Year')\n",
    "    station_water = dfWaterlevel[dfWaterlevel['station_id'] == station_id].sort_values('year')\n",
    "\n",
    "    # Initialize model\n",
    "    model = GeologicalSubsidenceModel(station_layers)\n",
    "\n",
    "    # Prepare water level changes dictionary\n",
    "    water_changes = station_water.set_index('year')['level_change_mean'].to_dict()\n",
    "\n",
    "    results = []\n",
    "    for _, row in station_subsidence.iterrows():\n",
    "        year = row['Year']\n",
    "        actual_change = row['yearly_change']\n",
    "\n",
    "        # Get current year water change\n",
    "        current_water_change = water_changes.get(year)\n",
    "\n",
    "        if pd.notna(current_water_change) and pd.notna(actual_change):\n",
    "            # Get previous years' changes\n",
    "            prev_changes = [water_changes.get(year - i) for i in range(1, lookback + 1)]\n",
    "\n",
    "            # Make prediction\n",
    "            predicted = model.predict_subsidence(\n",
    "                current_water_change,\n",
    "                prev_changes\n",
    "            )\n",
    "\n",
    "            results.append({\n",
    "                'year': year,\n",
    "                'predicted_subsidence': predicted,\n",
    "                'actual_subsidence': actual_change,\n",
    "                'water_change': current_water_change\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results) if results else None\n",
    "\n",
    "def analyze_all_stations(dfLayers, dfWaterlevel, dfSubsidence, lookback=2):\n",
    "    \"\"\"Analyze all stations and compile results\"\"\"\n",
    "    all_results = []\n",
    "    station_metrics = {}\n",
    "\n",
    "    stations = dfLayers['station_id'].unique()\n",
    "\n",
    "    for station in stations:\n",
    "        print(f\"Processing station: {station}\")\n",
    "\n",
    "        # Analyze station\n",
    "        station_results = analyze_station(station, dfLayers, dfWaterlevel, dfSubsidence, lookback)\n",
    "\n",
    "        if station_results is not None:\n",
    "            # Add station ID\n",
    "            station_results['station_id'] = station\n",
    "            all_results.append(station_results)\n",
    "\n",
    "            # Calculate metrics\n",
    "            predictions = station_results['predicted_subsidence']\n",
    "            actuals = station_results['actual_subsidence']\n",
    "\n",
    "            rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "            r2 = r2_score(actuals, predictions)\n",
    "\n",
    "            station_metrics[station] = {\n",
    "                'RMSE': rmse,\n",
    "                'R2': r2,\n",
    "                'n_predictions': len(station_results)\n",
    "            }\n",
    "\n",
    "    results_df = pd.concat(all_results, ignore_index=True)\n",
    "    metrics_df = pd.DataFrame(station_metrics).T\n",
    "\n",
    "    return results_df, metrics_df\n",
    "\n",
    "def plot_results(results_df, metrics_df):\n",
    "    \"\"\"Plot analysis results\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Scatter plot\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.scatter(results_df['actual_subsidence'],\n",
    "               results_df['predicted_subsidence'],\n",
    "               alpha=0.5)\n",
    "    plt.plot([-100, 100], [-100, 100], 'r--')  # Perfect prediction line\n",
    "    plt.xlabel('Actual Subsidence (mm)')\n",
    "    plt.ylabel('Predicted Subsidence (mm)')\n",
    "    plt.title('Predicted vs Actual Subsidence')\n",
    "\n",
    "    # Error histogram\n",
    "    plt.subplot(2, 2, 2)\n",
    "    errors = results_df['predicted_subsidence'] - results_df['actual_subsidence']\n",
    "    plt.hist(errors, bins=30)\n",
    "    plt.xlabel('Prediction Error (mm)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Error Distribution')\n",
    "\n",
    "    # Station performance\n",
    "    plt.subplot(2, 2, 3)\n",
    "    metrics_df['RMSE'].sort_values().plot(kind='bar')\n",
    "    plt.xlabel('Station')\n",
    "    plt.ylabel('RMSE (mm)')\n",
    "    plt.title('RMSE by Station')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # R² values\n",
    "    plt.subplot(2, 2, 4)\n",
    "    metrics_df['R2'].sort_values().plot(kind='bar')\n",
    "    plt.xlabel('Station')\n",
    "    plt.ylabel('R²')\n",
    "    plt.title('R² by Station')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the analysis\n",
    "results_df, metrics_df = analyze_all_stations(dfLayerajusted, dfWaterlevel, dfSubsidence, lookback=2)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nModel Performance Summary\")\n",
    "print(\"========================\")\n",
    "print(f\"\\nNumber of stations analyzed: {len(metrics_df)}\")\n",
    "print(f\"Total number of predictions: {len(results_df)}\")\n",
    "\n",
    "overall_rmse = np.sqrt(mean_squared_error(\n",
    "    results_df['actual_subsidence'],\n",
    "    results_df['predicted_subsidence']\n",
    "))\n",
    "overall_r2 = r2_score(\n",
    "    results_df['actual_subsidence'],\n",
    "    results_df['predicted_subsidence']\n",
    ")\n",
    "\n",
    "print(f\"\\nOverall RMSE: {overall_rmse:.2f} mm\")\n",
    "print(f\"Overall R²: {overall_r2:.3f}\")\n",
    "\n",
    "print(\"\\nStation Performance:\")\n",
    "print(metrics_df.sort_values('RMSE'))\n",
    "\n",
    "# Plot results\n",
    "plot_results(results_df, metrics_df)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('geological_model_predictions.csv', index=False)\n",
    "metrics_df.to_csv('geological_model_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "class ModelOptimizer:\n",
    "    def __init__(self, dfLayers, dfWaterlevel, dfSubsidence):\n",
    "        self.dfLayers = dfLayers\n",
    "        self.dfWaterlevel = dfWaterlevel\n",
    "        self.dfSubsidence = dfSubsidence\n",
    "        self.thickness_threshold = 2.0  # Minimum layer thickness\n",
    "\n",
    "    def _evaluate_model(self, params, station_layers, station_id):\n",
    "        \"\"\"Evaluate model with given parameters\"\"\"\n",
    "        thicknesses = params\n",
    "\n",
    "        # Update layer thicknesses\n",
    "        station_layers = station_layers.copy()\n",
    "        active_layers = thicknesses >= self.thickness_threshold\n",
    "\n",
    "        if not any(active_layers):\n",
    "            return float('inf')\n",
    "\n",
    "        # Update active layers\n",
    "        station_layers = station_layers[active_layers].copy()\n",
    "        station_layers['thickness'] = thicknesses[active_layers]\n",
    "\n",
    "        try:\n",
    "            # Initialize model\n",
    "            model = GeologicalSubsidenceModel(station_layers)\n",
    "\n",
    "            # Get station data\n",
    "            station_subsidence = self.dfSubsidence[self.dfSubsidence['station_id'] == station_id]\n",
    "            station_water = self.dfWaterlevel[self.dfWaterlevel['station_id'] == station_id]\n",
    "            water_changes = station_water.set_index('year')['level_change_mean'].to_dict()\n",
    "\n",
    "            predictions = []\n",
    "            actuals = []\n",
    "\n",
    "            # Make predictions\n",
    "            for _, row in station_subsidence.iterrows():\n",
    "                year = row['Year']\n",
    "                actual_change = row['yearly_change']\n",
    "\n",
    "                current_water_change = water_changes.get(year)\n",
    "                prev_changes = [water_changes.get(year - i) for i in range(1, 3)]\n",
    "\n",
    "                if pd.notna(current_water_change) and pd.notna(actual_change):\n",
    "                    predicted = model.predict_subsidence(current_water_change, prev_changes)\n",
    "                    predictions.append(predicted)\n",
    "                    actuals.append(actual_change)\n",
    "\n",
    "            if len(predictions) < 3:\n",
    "                return float('inf')\n",
    "\n",
    "            # Calculate RMSE (to minimize)\n",
    "            return np.sqrt(mean_squared_error(actuals, predictions))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in model evaluation: {str(e)}\")\n",
    "            return float('inf')\n",
    "\n",
    "    def optimize_station(self, station_id):\n",
    "        \"\"\"Optimize layer thicknesses for a station\"\"\"\n",
    "        print(f\"\\nOptimizing station: {station_id}\")\n",
    "\n",
    "        # Get station layers\n",
    "        station_layers = self.dfLayers[self.dfLayers['station_id'] == station_id].copy()\n",
    "        if len(station_layers) == 0:\n",
    "            print(f\"No layer data for station {station_id}\")\n",
    "            return None\n",
    "\n",
    "        initial_thicknesses = station_layers['thickness'].values\n",
    "\n",
    "        def objective(x):\n",
    "            return self._evaluate_model(x, station_layers, station_id)\n",
    "\n",
    "        # Set bounds for thicknesses (0 to 1000m)\n",
    "        bounds = [(0, 1000) for _ in range(len(initial_thicknesses))]\n",
    "\n",
    "        # Try multiple starting points\n",
    "        best_result = None\n",
    "        best_score = float('inf')\n",
    "\n",
    "        # Starting points: original and slightly modified thicknesses\n",
    "        starting_points = [\n",
    "            initial_thicknesses,\n",
    "            initial_thicknesses * 0.8,\n",
    "            initial_thicknesses * 1.2\n",
    "        ]\n",
    "\n",
    "        for start_point in starting_points:\n",
    "            try:\n",
    "                result = minimize(\n",
    "                    objective,\n",
    "                    start_point,\n",
    "                    method='SLSQP',\n",
    "                    bounds=bounds,\n",
    "                    options={'ftol': 1e-6, 'maxiter': 1000}\n",
    "                )\n",
    "\n",
    "                if result.success and result.fun < best_score:\n",
    "                    best_result = result\n",
    "                    best_score = result.fun\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Optimization error with starting point: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        if best_result is None:\n",
    "            return {\n",
    "                'station_id': station_id,\n",
    "                'success': False,\n",
    "                'original_thicknesses': initial_thicknesses,\n",
    "                'optimized_thicknesses': initial_thicknesses,\n",
    "                'active_layers': np.ones(len(initial_thicknesses), dtype=bool),\n",
    "                'original_rmse': objective(initial_thicknesses),\n",
    "                'optimized_rmse': objective(initial_thicknesses),\n",
    "                'n_layers_removed': 0\n",
    "            }\n",
    "\n",
    "        optimized_thicknesses = best_result.x\n",
    "        active_layers = optimized_thicknesses >= self.thickness_threshold\n",
    "\n",
    "        result = {\n",
    "            'station_id': station_id,\n",
    "            'success': True,\n",
    "            'original_thicknesses': initial_thicknesses,\n",
    "            'optimized_thicknesses': optimized_thicknesses,\n",
    "            'active_layers': active_layers,\n",
    "            'original_rmse': objective(initial_thicknesses),\n",
    "            'optimized_rmse': best_result.fun,\n",
    "            'n_layers_removed': np.sum(~active_layers)\n",
    "        }\n",
    "\n",
    "        self._print_optimization_results(result)\n",
    "        return result\n",
    "\n",
    "    def _print_optimization_results(self, result):\n",
    "        \"\"\"Print optimization results for a station\"\"\"\n",
    "        print(f\"\\nResults for station {result['station_id']}:\")\n",
    "        print(f\"Original RMSE: {result['original_rmse']:.6f}\")\n",
    "        print(f\"Optimized RMSE: {result['optimized_rmse']:.6f}\")\n",
    "        print(f\"Improvement: {result['original_rmse'] - result['optimized_rmse']:.6f}\")\n",
    "        print(f\"Layers removed: {result['n_layers_removed']}\")\n",
    "\n",
    "        print(\"\\nLayer Status:\")\n",
    "        print(\"Layer | Original (m) | Optimized (m) | Status\")\n",
    "        print(\"-\" * 45)\n",
    "        for i, (orig, opt, active) in enumerate(zip(\n",
    "            result['original_thicknesses'],\n",
    "            result['optimized_thicknesses'],\n",
    "            result['active_layers']\n",
    "        )):\n",
    "            status = \"Active\" if active else \"Removed\"\n",
    "            print(f\"{i+1:5d} | {orig:11.1f} | {opt:11.1f} | {status}\")\n",
    "\n",
    "def optimize_all_stations(dfLayers, dfWaterlevel, dfSubsidence):\n",
    "    \"\"\"Optimize all stations and return results\"\"\"\n",
    "    optimizer = ModelOptimizer(dfLayers, dfWaterlevel, dfSubsidence)\n",
    "    results = []\n",
    "\n",
    "    for station in dfLayers['station_id'].unique():\n",
    "        result = optimizer.optimize_station(station)\n",
    "        if result is not None:\n",
    "            results.append(result)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(\"\\nOptimization Summary\")\n",
    "    print(\"===================\")\n",
    "    print(f\"Total stations processed: {len(results_df)}\")\n",
    "\n",
    "    successful = results_df[results_df['success']]\n",
    "    if len(successful) > 0:\n",
    "        print(f\"Successful optimizations: {len(successful)}/{len(results_df)}\")\n",
    "        print(f\"Average RMSE improvement: {(successful['original_rmse'] - successful['optimized_rmse']).mean():.6f}\")\n",
    "        print(f\"Average layers removed: {successful['n_layers_removed'].mean():.1f}\")\n",
    "\n",
    "        # Distribution of removed layers\n",
    "        n_removed = successful['n_layers_removed'].value_counts().sort_index()\n",
    "        print(\"\\nDistribution of removed layers:\")\n",
    "        for n, count in n_removed.items():\n",
    "            print(f\"{n} layers removed: {count} stations\")\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optimization\n",
    "optimization_results = optimize_all_stations(dfLayers, dfWaterlevel, dfSubsidence)\n",
    "\n",
    "# Save results\n",
    "optimization_results.to_csv('optimization_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "def parse_array_string(array_string):\n",
    "    \"\"\"Parse string representation of array into numpy array\"\"\"\n",
    "    try:\n",
    "        # Remove any whitespace and convert to list\n",
    "        clean_string = array_string.strip('[]').replace('\\n', '')\n",
    "        return np.array([float(x) for x in clean_string.split()])\n",
    "    except:\n",
    "        return np.array([])\n",
    "\n",
    "def parse_boolean_array(array_string):\n",
    "    \"\"\"Parse string representation of boolean array\"\"\"\n",
    "    try:\n",
    "        # Convert string \"True\" and \"False\" to boolean values\n",
    "        clean_string = array_string.strip('[]').replace('\\n', '')\n",
    "        return np.array([x.strip().lower() == 'true' for x in clean_string.split()])\n",
    "    except:\n",
    "        return np.array([])\n",
    "\n",
    "def process_optimized_layers(input_df, optimization_df):\n",
    "    \"\"\"\n",
    "    Process layer data based on optimization results\n",
    "\n",
    "    Parameters:\n",
    "    input_df: DataFrame with original layer data\n",
    "    optimization_df: DataFrame with optimization results\n",
    "    \"\"\"\n",
    "    result_rows = []\n",
    "\n",
    "    # Process each station\n",
    "    for station_id in input_df['station_id'].unique():\n",
    "        # Get optimization data for this station\n",
    "        opt_row = optimization_df[optimization_df['station_id'] == station_id].iloc[0]\n",
    "\n",
    "        # Get station data\n",
    "        station_data = input_df[input_df['station_id'] == station_id]\n",
    "\n",
    "        # Parse the string representations into arrays\n",
    "        active_layers = parse_boolean_array(opt_row['active_layers'])\n",
    "        new_thicknesses = parse_array_string(opt_row['optimized_thicknesses'])\n",
    "\n",
    "        # Filter and update thicknesses\n",
    "        for idx, (is_active, new_thickness) in enumerate(zip(active_layers, new_thicknesses)):\n",
    "            if is_active and new_thickness > 1e-10:  # Filter out very small thicknesses\n",
    "                if idx < len(station_data):  # Check if index exists in station_data\n",
    "                    row = station_data.iloc[idx].copy()\n",
    "                    row['thickness'] = new_thickness\n",
    "                    result_rows.append(row)\n",
    "\n",
    "    # Create final dataframe\n",
    "    result_df = pd.DataFrame(result_rows)\n",
    "    return result_df\n",
    "\n",
    "# Example usage:\n",
    "# Read the input data (assuming this is your layer data)\n",
    "# dfLayers = pd.read_csv('original_layers.csv')\n",
    "\n",
    "# Read optimization results\n",
    "optimization_df = pd.read_csv('optimization_results.csv')\n",
    "\n",
    "# Process the data\n",
    "result_df = process_optimized_layers(dfLayers, optimization_df)\n",
    "\n",
    "# Save to CSV\n",
    "result_df.to_csv('optimized_layers.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
